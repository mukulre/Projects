{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6RPQTsGxpmeHzl//xsCAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukulre/Projects/blob/main/Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UjyMH_6NhtlW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "from heapq import nlargest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from heapq import nlargest\n",
        "\n",
        "# Download necessary NLTK datasets\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Download the punkt_tab dataset\n",
        "\n",
        "# Replace this with your actual text\n",
        "text = \"\"\"Your long text goes here. It should contain enough sentences for summarization.\n",
        "Make sure this text is sufficiently long to test the summarization algorithm properly.\n",
        "Add more sentences as needed to create a meaningful summary.\"\"\"\n",
        "\n",
        "if text.count(\". \") > 20:\n",
        "    length = int(round(text.count(\". \") / 10, 0))\n",
        "else:\n",
        "    length = min(3, text.count(\". \"))  # Ensure at least 1 and at most 3 sentences\n",
        "\n",
        "# Remove punctuation\n",
        "nopuch = [char for char in text if char not in string.punctuation]\n",
        "nopuch = \"\".join(nopuch)\n",
        "\n",
        "# Process text: remove stopwords\n",
        "processed_text = [word for word in nopuch.split() if word.lower() not in nltk.corpus.stopwords.words('english')]\n",
        "\n",
        "# Calculate word frequencies\n",
        "word_freq = {}\n",
        "for word in processed_text:\n",
        "    word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "max_freq = max(word_freq.values(), default=0)  # Handle case when max_freq is empty\n",
        "for word in word_freq.keys():\n",
        "    word_freq[word] = (word_freq[word] / max_freq) if max_freq > 0 else 0\n",
        "\n",
        "# Tokenize sentences\n",
        "sent_list = nltk.sent_tokenize(text)\n",
        "sent_score = {}\n",
        "for sent in sent_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_freq.keys():\n",
        "            sent_score[sent] = sent_score.get(sent, 0) + word_freq[word]\n",
        "\n",
        "# Get the top scoring sentences\n",
        "summary_sents = nlargest(length, sent_score, key=sent_score.get)\n",
        "summary = \" \".join(summary_sents)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ6QBQ8qma2j",
        "outputId": "adf7b746-9700-4fe5-dd2a-74162cd92125"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make sure this text is sufficiently long to test the summarization algorithm properly.\n"
          ]
        }
      ]
    }
  ]
}